{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937cae5f",
   "metadata": {},
   "source": [
    "# Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc38cff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mStringObjectParser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringObjectParser\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstats\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from util.StringObjectParser import StringObjectParser\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66708346",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59a4d5",
   "metadata": {},
   "source": [
    "## NL to SQL Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6aa638",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(f\"The current working directory is: {current_directory}\")\n",
    "data_directory = current_directory.replace(\"/src\", \"/nl_sql_results\")\n",
    "\n",
    "xlsx_files = [file for file in os.listdir(data_directory) if file.endswith(\".xlsx\")]\n",
    "dataframes = []\n",
    "for xf in xlsx_files:\n",
    "    df = pd.read_excel(os.path.join(data_directory, xf))\n",
    "    xf_bits = xf.split(\"-\")\n",
    "    df[\"subsetting_method\"] = xf_bits[1]\n",
    "    df[\"benchmark\"] = xf_bits[2]\n",
    "    df[\"comments\"] = xf_bits[4].replace(\".xlsx\", \"\")\n",
    "    dataframes.append(df)\n",
    "nlsql_performance_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5611e72",
   "metadata": {},
   "source": [
    "## Subsetting Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f75c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(f\"The current working directory is: {current_directory}\")\n",
    "data_directory = current_directory.replace(\"/src\", \"/subsetting_results\")\n",
    "\n",
    "xlsx_files = [file for file in os.listdir(data_directory) if file.endswith('.xlsx')]\n",
    "dataframes = []\n",
    "for xf in xlsx_files:\n",
    "    df = pd.read_excel(os.path.join(data_directory, xf))\n",
    "    df[\"subsetting_method\"] = xf.split(\"-\")[1]\n",
    "    df[\"benchmark\"] = xf.split(\"-\")[2]\n",
    "    df[\"comments\"] = xf.split(\"-\")[4].replace(\".xlsx\", \"\")\n",
    "    dataframes.append(df)\n",
    "subset_performance_df = pd.concat(dataframes, ignore_index=True)\n",
    "for column in subset_performance_df.columns:\n",
    "    processed_objs = []\n",
    "    for val in subset_performance_df[column]:\n",
    "        obj = StringObjectParser.string_to_python_object(val, use_eval=True)\n",
    "        if type(obj) == str and obj[0] == \"{\":\n",
    "            obj = set([v.strip() for v in obj.replace(\"{\", \"\").replace(\"}\", \"\").split(\",\")])\n",
    "        processed_objs.append(obj)\n",
    "    subset_performance_df[column] = processed_objs\n",
    "        # subset_performance_df[column] = subset_performance_df[column].apply(\n",
    "        #     lambda x: StringObjectParser.string_to_python_object(x, use_eval=True) if StringObjectParser.check_valid_container(x) or x == \"set()\" else x\n",
    "        # )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6618ab",
   "metadata": {},
   "source": [
    "## Schema Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = f\"{os.getcwd()}/benchmark_schema_stats\"\n",
    "data_directory = current_directory.replace(\"/src\", \"/subsetting_results\")\n",
    "\n",
    "json_files = [file for file in os.listdir(data_directory) if file.endswith('_stats.json')]\n",
    "df_dict = {\"benchmark\": [], \"database\": [], \"table_count\": [], \"column_count\": []}\n",
    "for filename in json_files:\n",
    "    fn_split = filename.split(\"_\")\n",
    "    stat_dict = json.loads(open(f\"{data_directory}/{filename}\", \"r\").read())\n",
    "    for k in stat_dict:\n",
    "        df_dict[\"benchmark\"].append(fn_split[0])\n",
    "        df_dict[\"database\"].append(k)\n",
    "        df_dict[\"table_count\"].append(stat_dict[k][\"table_count\"])\n",
    "        df_dict[\"column_count\"].append(stat_dict[k][\"column_count\"])\n",
    "schema_stat_df = pd.DataFrame(df_dict).query(\"benchmark!='abstract'\")\n",
    "for column in schema_stat_df.columns:\n",
    "    schema_stat_df[column] = schema_stat_df[column].apply(\n",
    "        lambda x: StringObjectParser.string_to_python_object(x, use_eval=True) if StringObjectParser.check_valid_container(x) or x == \"set()\" else x\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7269795a",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113ce7b",
   "metadata": {},
   "source": [
    "## Model Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_model_filter = {\n",
    "    \"CodeS\": \"lambda1_sic_merged\",\n",
    "    \"DINSQL\": \"gpt41\",\n",
    "    \"chess\": \"gpt4o\",\n",
    "    \"crush4sql\": \"lambda1\",\n",
    "    \"dtssql\": \"lambda1\",\n",
    "    \"rslsql\": \"gpt41\",\n",
    "    \"tasql\": \"gpt41\",\n",
    "    # \"skalpel\": \"vector_qdecomp_525th\",\n",
    "    \"skalpel\": \"do not eval\",\n",
    "    \"skalpeltasql\": \"gpt41nano-vectorsort\",\n",
    "    \"perfect_subsetter\": \"oracle\",\n",
    "    \"perfect_table_subsetter\": \"oracle\",\n",
    "    \"nosubset\": \"fullschema\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc905f5",
   "metadata": {},
   "source": [
    "## Display Data Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetting_display_names = {\n",
    "    \"crush4sql\": \"Crush\",\n",
    "    \"rslsql\": \"RSLSQL\",\n",
    "    \"tasql\": \"TASQL\",\n",
    "    \"CodeS\": \"CodeS\",\n",
    "    \"dtssql\": \"DTSSQL\",\n",
    "    \"chess\": \"CHESS\",\n",
    "    \"DINSQL\": \"DINSQL\",\n",
    "    \"skalpel\": \"Skalpel\",\n",
    "    \"skalpeltasql\": \"Skalpel+TASQL\",\n",
    "    \"perfect_subsetter\": \"Perfect\",\n",
    "    \"perfect_table_subsetter\": \"Perfect-Table\",\n",
    "    \"nosubset\": \"FullSchema\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c391d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetting_classifications = {\n",
    "    \"crush4sql\": \"Hyb\",\n",
    "    \"rslsql\": \"LLM\",\n",
    "    \"tasql\": \"LLM\",\n",
    "    \"CodeS\": \"ML\",\n",
    "    \"dtssql\": \"LLM\",\n",
    "    \"chess\": \"Hyb\",\n",
    "    \"DINSQL\": \"LLM\",\n",
    "    \"Skalpel\": \"Hyb\",\n",
    "    \"Skalpel+TASQL\": \"Hyb\",\n",
    "    \"perfect_subsetter\": \"Oracle\",\n",
    "    \"perfect_table_subsetter\": \"Oracle\",\n",
    "    \"nosubset\": \"Full\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171361ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetting_display_order = {\n",
    "    \"Crush\": 80,\n",
    "    \"RSLSQL\": 40,\n",
    "    \"TASQL\": 50,\n",
    "    \"CodeS\": 90,\n",
    "    \"DTSSQL\": 100,\n",
    "    \"CHESS\": 70,\n",
    "    \"DINSQL\": 60,\n",
    "    \"Skalpel\": 30,\n",
    "    \"Skalpel+TASQL\": 35,\n",
    "    \"Perfect\": 10,\n",
    "    \"Perfect-Table\": 20,\n",
    "    \"FullSchema\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d591737",
   "metadata": {},
   "source": [
    "## Process Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83193a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsql_performance_df[\"Subsetting Method\"] = nlsql_performance_df.subsetting_method.apply(lambda x: subsetting_display_names[x])\n",
    "subset_performance_df[\"Subsetting Method\"] = subset_performance_df.subsetting_method.apply(lambda x: subsetting_display_names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d25a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsql_performance_df[\"eval_model\"] = nlsql_performance_df.apply(\n",
    "    lambda row: row.comments == comment_model_filter[row.subsetting_method], \n",
    "    axis=1\n",
    "    )\n",
    "subset_performance_df[\"eval_model\"] = subset_performance_df.apply(\n",
    "    lambda row: row.comments == comment_model_filter[row.subsetting_method], \n",
    "    axis=1\n",
    "    )\n",
    "nlsql_performance_df[\"nl_sql_model\"] = nlsql_performance_df.nl_sql_model.fillna(\"openai/gpt-oss-120b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsql_performance_df[\"method_order\"] = nlsql_performance_df[\"Subsetting Method\"].apply(\n",
    "    lambda x: subsetting_display_order[x]\n",
    "    )\n",
    "nlsql_performance_df[\"has_generated_query\"] = nlsql_performance_df.generated_query.fillna(\"doh\").apply(lambda x: x != \"doh\" and x != 'Token limited exceeded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d99cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_performance_df[\"perfect_recall\"] = subset_performance_df.total_recall.apply(lambda x: 1 if x == 1.0 else 0)\n",
    "subset_performance_df[\"empty_subset\"] = subset_performance_df.apply(\n",
    "    lambda row: len(row.correct_tables)==0 and len(row.extra_tables)==0,\n",
    "    axis=1\n",
    "    )\n",
    "subset_performance_df[\"subset_table_count\"] = subset_performance_df.apply(lambda row: len(row.correct_tables) + len(row.extra_tables), axis=1)\n",
    "subset_performance_df[\"subset_column_count\"] = subset_performance_df.apply(lambda row: len(row.correct_columns) + len(row.extra_columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 10/503 [00:03<02:48,  2.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     12\u001b[0m bm_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubset_column_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m     32\u001b[0m }\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m tqdm(bm):\n\u001b[0;32m---> 34\u001b[0m     subset \u001b[38;5;241m=\u001b[39m \u001b[43mss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_schema_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_from_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subset\u001b[38;5;241m.\u001b[39mschema_subset\u001b[38;5;241m.\u001b[39mtables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(question\u001b[38;5;241m.\u001b[39mquery)\n",
      "File \u001b[0;32m/data/kluoma/skalpel-subsetting-evaluation/src/SchemaSubsetter/Perfect/PerfectSchemaSubsetter.py:50\u001b[0m, in \u001b[0;36mPerfectSchemaSubsetter.get_schema_subset\u001b[0;34m(self, benchmark_question, load_from_cache)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     49\u001b[0m full_schema \u001b[38;5;241m=\u001b[39m benchmark_question\u001b[38;5;241m.\u001b[39mschema\n\u001b[0;32m---> 50\u001b[0m query_identifiers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_profiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_identifiers_and_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark_question\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark_question\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_brackets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# print(\"DEBUG get_schema_subset query_identifiers:\", query_identifiers)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m query_tables \u001b[38;5;241m=\u001b[39m query_identifiers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/data/kluoma/skalpel-subsetting-evaluation/src/SubsetEvaluator/QueryProfiler.py:68\u001b[0m, in \u001b[0;36mQueryProfiler.get_identifiers_and_labels\u001b[0;34m(self, query, distinct, include_brackets, dialect)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery\n\u001b[0;32m---> 68\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofile_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     69\u001b[0m tables \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m columns \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/data/kluoma/skalpel-subsetting-evaluation/src/SubsetEvaluator/QueryProfiler.py:52\u001b[0m, in \u001b[0;36mQueryProfiler.profile_query\u001b[0;34m(self, query, dialect)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprofile_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, dialect: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__parse_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msyntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery \u001b[38;5;241m=\u001b[39m query\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/data/kluoma/skalpel-subsetting-evaluation/src/SubsetEvaluator/QueryProfiler.py:261\u001b[0m, in \u001b[0;36mQueryProfiler.__parse_query\u001b[0;34m(self, query, syntax)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    260\u001b[0m     query_to_parse \u001b[38;5;241m=\u001b[39m query_to_parse\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m encoded_response \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjava -jar \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{j}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m --query \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{q}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m --dialect \u001b[39;49m\u001b[38;5;132;43;01m{s}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__jar_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquery_to_parse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msyntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_shell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    271\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(encoded_response)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# print(\"__parse_query DEBUG:\", response)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from NlSqlBenchmark.NlSqlBenchmarkFactory import NlSqlBenchmarkFactory\n",
    "from SchemaSubsetter.Perfect.PerfectSchemaSubsetter import PerfectSchemaSubsetter\n",
    "from SubsetEvaluator.SchemaSubsetEvaluator import SchemaSubsetEvaluator, SubsetEvaluation\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "current_directory = os.getcwd()\n",
    "os.chdir(current_directory.replace(\"/src\", \"/\"))\n",
    "fact = NlSqlBenchmarkFactory()\n",
    "for bm_name in [\"snails\", \"bird\", \"spider2\"]:\n",
    "    bm = fact.build_benchmark(bm_name)\n",
    "    ss = PerfectSchemaSubsetter(fact.build_benchmark(bm_name))\n",
    "    evaluator = SchemaSubsetEvaluator(use_result_cache=False)\n",
    "    bm_data = {\n",
    "        \"database\": [],\n",
    "        \"question_number\": [],\n",
    "        \"total_precision\": [],\n",
    "        \"total_f1\": [],\n",
    "        \"table_recall\": [],\n",
    "        \"table_precision\": [],\n",
    "        \"table_f1\": [],\n",
    "        \"column_recall\": [],\n",
    "        \"column_f1\": [],\n",
    "        \"subset_table_proportion\": [],\n",
    "        \"subset_column_proportion\": [],\n",
    "        \"subsetting_method\": [],\n",
    "        \"benchmark\": [],\n",
    "        \"comments\": [],\n",
    "        \"eval_model\": [],\n",
    "        \"perfect_recall\": [],\n",
    "        \"empty_subset\": [],\n",
    "        \"subset_table_count\": [],\n",
    "        \"subset_column_count\": []\n",
    "    }\n",
    "    for question in tqdm(bm):\n",
    "        subset = ss.get_schema_subset(question, load_from_cache=False)\n",
    "        if len(subset.schema_subset.tables) == 0:\n",
    "            print(question.query)\n",
    "        bm_data[\"database\"].append(question.schema.database)\n",
    "        bm_data[\"question_number\"].append(question.question_number)\n",
    "        evaluation = evaluator.evaluate_schema_subset(subset, question)\n",
    "        bm_data[\"total_precision\"] = evaluation.total_precision\n",
    "\n",
    "        \n",
    "os.chdir(current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e4f1b",
   "metadata": {},
   "source": [
    "## Process Schema Stat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_sizes = {\n",
    "    # 100: \"s\",\n",
    "    1000: \"s-m\",\n",
    "    100000: \"l+\",\n",
    "    # 50000: \"xl\",\n",
    "    # 100000: \"xxl\"\n",
    "}\n",
    "\n",
    "def get_size(x: int) -> str:\n",
    "    for s in schema_sizes.keys():\n",
    "        if x < s:\n",
    "            return schema_sizes[s]\n",
    "\n",
    "schema_size_map = {\n",
    "    schema_sizes[k] : k for k in schema_sizes.keys()\n",
    "}\n",
    "\n",
    "schema_stat_df[\"size_cat\"] = schema_stat_df.column_count.apply(\n",
    "    lambda x: get_size(x) \n",
    "    )\n",
    "schema_stat_df[\"size_descr\"] = schema_stat_df.size_cat.apply(\n",
    "    lambda x: f\"col<{schema_size_map[x]:,}\"\n",
    ")\n",
    "schema_stat_df[\"size_sort\"] = schema_stat_df.size_cat.apply(\n",
    "    lambda x: schema_size_map[x]\n",
    ")\n",
    "\n",
    "schema_stat_df[\"mean_table_size\"] = schema_stat_df.apply(\n",
    "    lambda row: row.column_count / row.table_count,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67909766",
   "metadata": {},
   "source": [
    "# Failed NL to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb550e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_index = [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "temp_data_df = nlsql_performance_df.set_index(join_index).join(\n",
    "    subset_performance_df.set_index(join_index),\n",
    "    lsuffix=\"_l\", rsuffix=\"_r\"\n",
    ").reset_index()\n",
    "temp_data_df[\"generated_query\"] = temp_data_df.generated_query.fillna(\"no query\")\n",
    "temp_data_df.query(\n",
    "    \"eval_model_l and (generated_query=='Token limited exceeded' or generated_query=='no query') and empty_subset==False\"\n",
    "    )[[\"nl_sql_model\", \"subsetting_method\", \"database\", \"gold_query\"]].groupby([\n",
    "    \"nl_sql_model\", \"subsetting_method\", \"database\"\n",
    "]).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed872b30",
   "metadata": {},
   "source": [
    "# Execution Accuracy for Each Subsetting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=nlsql_performance_df.query(\"eval_model and has_generated_query\").set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).sort_values(by=[\"method_order\", \"size_sort\"]),\n",
    "    x=\"nl_sql_model\",\n",
    "    y=\"result_set_match\",\n",
    "    kind=\"bar\",\n",
    "    hue=\"subsetting_method\",\n",
    "    aspect=5,\n",
    "    # col=\"size_cat\",\n",
    "    # col_wrap=1,\n",
    "    legend_out=False,\n",
    "    # legend=False\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(0.48, -0.26), loc='lower center', borderaxespad=0, ncols=11, fontsize=16)\n",
    "g.set_axis_labels(\"NL SQL LLM\", \"Execution Accuracy\", fontsize=18)\n",
    "g.set_xticklabels(fontsize=16)\n",
    "g.set_axis_labels(\"NL SQL LLM\", \"Execution Accuracy\")\n",
    "g.figure.savefig(\"../nl_sql_results/figures/nlsql_execution_accuracy_barchart.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e207291",
   "metadata": {},
   "source": [
    "## Execution accuracy by benchmark, LLM, and subsetting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40745b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsql_performance_df.nl_sql_model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=nlsql_performance_df.query(\"eval_model and has_generated_query\").sort_values(by=\"method_order\"),\n",
    "    x=\"nl_sql_model\",\n",
    "    y=\"result_set_match\",\n",
    "    kind=\"bar\",\n",
    "    hue=\"subsetting_method\",\n",
    "    aspect=3,\n",
    "    col=\"benchmark\",\n",
    "    col_wrap=1,\n",
    "    legend_out=False,\n",
    "    # legend=False\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(0.45, -0.26), loc='lower center', borderaxespad=0, ncols=11)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd28121",
   "metadata": {},
   "source": [
    "## Execution Accuracy by Benchmark, LLM, and Database Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=nlsql_performance_df.query(\"eval_model and has_generated_query\").set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).sort_values(by=[\"method_order\", \"size_sort\"]),\n",
    "    x=\"nl_sql_model\",\n",
    "    y=\"result_set_match\",\n",
    "    kind=\"bar\",\n",
    "    hue=\"subsetting_method\",\n",
    "    aspect=5,\n",
    "    col=\"size_cat\",\n",
    "    col_wrap=1,\n",
    "    legend_out=True,\n",
    "    # legend=False\n",
    ")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0.48, -0.26), loc='lower center', borderaxespad=0, ncols=11, fontsize=16)\n",
    "g._legend.remove()\n",
    "g.set_axis_labels(\"NL SQL LLM\", \"Execution Accuracy\", fontsize=18)\n",
    "for ax in g.axes.flat:    \n",
    "    ax.set_title(ax.get_title().replace(\"size_cat\", \"Database Size\"), fontsize=18)\n",
    "g.figure.savefig(\"../nl_sql_results/figures/nlsql_execution_accuracy_barchart_sizes.pdf\", bbox_inches=\"tight\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.axes_dict[\"l+\"].set_xlabel(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501ecfe",
   "metadata": {},
   "source": [
    "# Subsetting - NlSQL Performance Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b374f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_df = subset_performance_df.set_index(\n",
    "    [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "    ).join(\n",
    "        nlsql_performance_df.set_index(\n",
    "        [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "        ),\n",
    "        lsuffix=\"l_\", rsuffix=\"r_\"\n",
    "    ).reset_index().set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a852f27",
   "metadata": {},
   "source": [
    "## Recall x Execution Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_df = subset_performance_df.set_index(\n",
    "    [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "    ).join(\n",
    "        nlsql_performance_df.set_index(\n",
    "        [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "        ),\n",
    "        lsuffix=\"_l\", rsuffix=\"_r\"\n",
    "    ).reset_index().set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).reset_index().query(\"eval_model_l\")\n",
    "sns.barplot(\n",
    "    data=temp_data_df,\n",
    "    x=temp_data_df.total_recall.round(1),\n",
    "    y=\"result_set_match\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5073d7",
   "metadata": {},
   "source": [
    "## Precision x Execution Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_df = subset_performance_df.set_index(\n",
    "    [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "    ).join(\n",
    "        nlsql_performance_df.set_index(\n",
    "        [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "        ),\n",
    "        lsuffix=\"_l\", rsuffix=\"_r\"\n",
    "    ).reset_index().set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).reset_index().query(\"eval_model_l and has_generated_query\")\n",
    "sns.barplot(\n",
    "    data=temp_data_df,\n",
    "    x=temp_data_df.total_precision.round(1),\n",
    "    y=\"result_set_match\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66131a17",
   "metadata": {},
   "source": [
    "## Table proportion x Execution Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a72ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_df = subset_performance_df.set_index(\n",
    "    [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "    ).join(\n",
    "        nlsql_performance_df.set_index(\n",
    "        [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "        ),\n",
    "        lsuffix=\"_l\", rsuffix=\"_r\"\n",
    "    ).reset_index().set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).reset_index()\n",
    "sns.barplot(\n",
    "    data=temp_data_df.query(\"subset_table_proportion <= 1\"),\n",
    "    x=temp_data_df.query(\"subset_table_proportion <= 1 and eval_model_l and has_generated_query\").subset_table_proportion.round(1),\n",
    "    y=\"result_set_match\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b240055",
   "metadata": {},
   "source": [
    "## Table count x Execution Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ad36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_df = subset_performance_df.set_index(\n",
    "    [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "    ).join(\n",
    "        nlsql_performance_df.set_index(\n",
    "        [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "        ),\n",
    "        lsuffix=\"_l\", rsuffix=\"_r\"\n",
    "    ).reset_index().set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).reset_index()\n",
    "sns.barplot(\n",
    "    data=temp_data_df.query(\"eval_model_l and has_generated_query\"),\n",
    "    x=\"subset_table_count\",\n",
    "    y=\"result_set_match\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288dac8",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f4002",
   "metadata": {},
   "source": [
    "### All subsetting metrics predict execution accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca07f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "temp_data_df = subset_performance_df.set_index(\n",
    "    [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "    ).join(\n",
    "        nlsql_performance_df.set_index(\n",
    "        [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "        ),\n",
    "        lsuffix=\"_l\", rsuffix=\"_r\"\n",
    "    ).reset_index().set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).reset_index().query(\"eval_model_l and has_generated_query\").dropna()\n",
    "temp_data_df['result_set_match_numeric'] = temp_data_df['result_set_match'].astype(int)\n",
    "temp_data_df[\"schema_size_numeric\"] = temp_data_df.size_cat.apply(lambda x: {\n",
    "    \"s\": 1,\n",
    "    \"m\": 2,\n",
    "    \"s-m\": 1.5,\n",
    "    \"l\": 3,\n",
    "    \"l+\": 3,\n",
    "    \"xl\": 4,\n",
    "    \"xxl\": 5\n",
    "}[x])\n",
    "\n",
    "X = temp_data_df[[\n",
    "    \"perfect_recall\",\n",
    "    \"table_recall\",\n",
    "    \"table_precision\",\n",
    "    \"column_recall\",\n",
    "    \"column_precision\",\n",
    "    \"subset_table_count\",\n",
    "    \"subset_column_count\",\n",
    "    \"schema_size_numeric\"\n",
    "    ]]\n",
    "y = temp_data_df['result_set_match_numeric']\n",
    "X = sm.add_constant(X)\n",
    "logit_model = sm.Logit(y, X).fit()\n",
    "\n",
    "# Print the summary of the logistic regression model\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebe048",
   "metadata": {},
   "source": [
    "### Only perfect recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "temp_data_df = subset_performance_df.set_index(\n",
    "    [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "    ).join(\n",
    "        nlsql_performance_df.set_index(\n",
    "        [\"subsetting_method\", \"benchmark\", \"database\", \"question_number\"]\n",
    "        ),\n",
    "        lsuffix=\"_l\", rsuffix=\"_r\"\n",
    "    ).reset_index().set_index([\"benchmark\", \"database\"]).join(\n",
    "        schema_stat_df.set_index([\"benchmark\", \"database\"])\n",
    "    ).reset_index().query(\"perfect_recall == 1 and eval_model_l and has_generated_query\").dropna()\n",
    "temp_data_df['result_set_match_numeric'] = temp_data_df['result_set_match'].astype(int)\n",
    "temp_data_df[\"schema_size_numeric\"] = temp_data_df.size_cat.apply(lambda x: {\n",
    "    \"s\": 1,\n",
    "    \"s-m\": 1.5,\n",
    "    \"m\": 2,\n",
    "    \"l\": 3,\n",
    "    \"l+\": 3,\n",
    "    \"xl\": 4,\n",
    "    \"xxl\": 5\n",
    "}[x])\n",
    "\n",
    "X = temp_data_df[[\n",
    "    \"subset_table_count\", \n",
    "    \"schema_size_numeric\"\n",
    "    ]]\n",
    "y = temp_data_df['result_set_match_numeric']\n",
    "X = sm.add_constant(X)\n",
    "logit_model = sm.Logit(y, X).fit()\n",
    "\n",
    "# Print the summary of the logistic regression model\n",
    "print(logit_model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
